{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import Algorithms.baselines as base\n",
    "import Algorithms.context_knn as cknn\n",
    "import Algorithms.SeqContextKNN as scknn\n",
    "import Algorithms.gru4rec as gru4rec\n",
    "import Algorithms.svmknn as svmknn\n",
    "import time\n",
    "import pickle\n",
    "import argparse\n",
    "import os\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainBPR(lambda_session,lambda_item):\n",
    "    algo = base.BPR(lambda_session = lambda_session,lambda_item = lambda_item)\n",
    "\n",
    "    print(\"Training algorithm: BPR with lambda_session {} and lambda_item {}\".format(lambda_session,lambda_item))\n",
    "\n",
    "    algo.fit(train)\n",
    "\n",
    "    # save the model to disk\n",
    "    filename = \"models/valid/cb12_BPR_ls\"  + str(lambda_session) + 'li'+ str(lambda_item) + \".model\"\n",
    "    os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
    "    print(\"Finished training. Storing model to: \" + filename)\n",
    "    with open(filename,'wb') as f:\n",
    "        pickle.dump(algo,f)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIKNN(lmbd,alpha):\n",
    "    algo = base.ItemKNN(lmbd=lmbd, alpha=alpha)\n",
    "\n",
    "    print(\"Training algorithm: ItemKNN with lambda {} and alpha {}\".format(lmbd,alpha))\n",
    "\n",
    "    algo.fit(train)\n",
    "\n",
    "    # save the model to disk\n",
    "    filename = \"models/valid/cb12_IKNN_lmbd\" + str(lmbd) + 'alpha' + str(alpha) + \".model\"\n",
    "    os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
    "    print(\"Finished training. Storing model to: \" + filename)\n",
    "    with open(filename,'wb') as f:\n",
    "        pickle.dump(algo,f)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainSKNN(k, sampling, similarity, pop_boost):\n",
    "    \"\"\"\n",
    "    Also known as context knn or cknn\n",
    "    k = 500\n",
    "    sampling = 1000\n",
    "    \"\"\"\n",
    "    algo = cknn.ContextKNN(k = k, sampling=sampling, similarity = similarity, pop_boost = pop_boost)\n",
    "\n",
    "    print(\"Training algorithm: SKNN with k {}, sampling {}, similarity {} and pop_boost {}\".format(k, sampling, similarity,\n",
    "                                                                                                pop_boost))\n",
    "\n",
    "    algo.fit(train)\n",
    "\n",
    "    # save the model to disk\n",
    "    filename = \"models/valid/cb12_SKNN_k\" + str(k) + 'Smpl' + str(sampling) + 'Sim' + str(similarity) + 'Pop_boost' + str(pop_boost) + \".model\"\n",
    "    os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
    "    print(\"Finished training. Storing model to: \" + filename)\n",
    "    with open(filename,'wb') as f:\n",
    "        pickle.dump(algo,f)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainSsKNN(k,sampling,similarity,pop_boost):\n",
    "\n",
    "    \"\"\"\n",
    "    Also known as sequental context KNN\n",
    "    k = 500\n",
    "    sampling = 1000\n",
    "    \"\"\"\n",
    "\n",
    "    algo = scknn.SeqContextKNN(k=k, sampling=sampling, similarity = similarity, pop_boost = pop_boost)\n",
    "\n",
    "    print(\"Training algorithm: S-sKNN with k {}, sampling {}, similarity {} and pop_boost {}\".format(k, sampling, similarity,\n",
    "                                                                                                pop_boost))\n",
    "\n",
    "    algo.fit(train)\n",
    "\n",
    "    # save the model to disk\n",
    "    filename = \"models/valid/cb12_S-sKNN_k\" + str(k) + 'Smpl' + str(sampling) + 'Sim' + str(similarity) + 'Pop_boost' + str(pop_boost) + \".model\"\n",
    "    os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
    "    print(\"Finished training. Storing model to: \" + filename)\n",
    "    with open(filename,'wb') as f:\n",
    "        pickle.dump(algo,f)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainSVMKNN(k,sampling,similarity,pop_boost,weighting):\n",
    "    \"\"\"\n",
    "    k = 500\n",
    "    sampling = 1000\n",
    "    \"\"\"\n",
    "\n",
    "    algo = svmknn.VMContextKNN(k=k, sampling=sampling, similarity = similarity, pop_boost = pop_boost, weighting = weighting)\n",
    "\n",
    "    print(\"Training algorithm: SVMKNN with k {}, sampling {}, similarity {}, pop_boost {} and weighting {}\".format(k, sampling, similarity,\n",
    "                                                                                                pop_boost, weighting))\n",
    "\n",
    "    algo.fit(train)\n",
    "\n",
    "    # save the model to disk\n",
    "    filename = \"models/valid/cb12_SVMKNN_k\" + str(k) + 'Smpl' + str(sampling) + 'Sim' + str(similarity) + 'Pop_boost' + str(pop_boost) \\\n",
    "        + 'WeiFun' + weighting + \".model\"\n",
    "    os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
    "    print(\"Finished training. Storing model to: \" + filename)\n",
    "    with open(filename,'wb') as f:\n",
    "        pickle.dump(algo,f)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainGRU4Rec(loss, layers, dropout_p_hidden, batch_size):\n",
    "    # save the model to disk\n",
    "    layers_str = '_'.join(str(x) for x in layers)\n",
    "    params = '_loss' + loss + '_layers' + layers_str  + '_drop' + str(dropout_p_hidden) + '_batch' + str(batch_size)\n",
    "    filename = \"models/valid/cb12_GRU4Rec\" + params + \".model\"\n",
    "    if os.path.isfile(filename):\n",
    "        print(\"cb12_GRU4Rec\" + params + \".model already exists. Skipping training.\")\n",
    "        return\n",
    "\n",
    "    algo = gru4rec.GRU4Rec(\n",
    "        loss=loss,\n",
    "        final_act='linear', \n",
    "        hidden_act='tanh', \n",
    "        layers=layers, \n",
    "        batch_size=batch_size, \n",
    "        dropout_p_hidden=dropout_p_hidden, \n",
    "        learning_rate=0.2, \n",
    "        momentum=0.0, \n",
    "        n_sample=2048, \n",
    "        sample_alpha=0, \n",
    "        time_sort=True\n",
    "    )\n",
    "\n",
    "    print(\"Training algorithm: GRU4Rec with loss {}, layers {}, dropout {} and batch size {}\".format(loss, layers_str, dropout_p_hidden, batch_size))\n",
    "\n",
    "    algo.fit(train)\n",
    "\n",
    "    os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
    "    print(\"Finished training. Storing model to: \" + filename)\n",
    "    with open(filename,'wb') as f:\n",
    "        pickle.dump(algo,f)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '../../data/cb12/processed/valid_train_14d.csv'\n",
    "train = pd.read_csv(train_path, sep='\\t')[['session_id', 'item_id', 'created_at']]\n",
    "train.columns = ['SessionId', 'ItemId', 'Time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training GRU4Rec models\n",
    "loss = [\"top1-max\", \"bpr-max-0.5\"]\n",
    "layers = [[100], [100,100], [1000], [1000,1000]]\n",
    "dropout_p_hidden = [0.0, 0.2, 0.5]\n",
    "batch_size = [32, 128, 512]\n",
    "gru_params = list(itertools.product(loss, layers, dropout_p_hidden, batch_size))\n",
    "for i in range (len(gru_params)):\n",
    "    trainGRU4Rec(gru_params[i][0], gru_params[i][1], gru_params[i][2], gru_params[i][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training BPR models\n",
    "lambda_session = [0, 0.25, 0.5]\n",
    "lambda_item = [0, 0.25, 0.5]\n",
    "bpr_params = list(itertools.product(lambda_session, lambda_item))\n",
    "for i in range (len(bpr_params)):\n",
    "    trainBPR(bpr_params[i][0], bpr_params[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training IKNN models\n",
    "lambd = [20, 50, 80]\n",
    "alpha = [0.25, 0.5, 0.75]\n",
    "iknn_params = list(itertools.product(lambd, alpha))\n",
    "for i in range(len(iknn_params)):\n",
    "    trainIKNN(iknn_params[i][0], iknn_params[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training sKNN\n",
    "\n",
    "k = [100, 200, 500, 1000]\n",
    "sampling = [\"recent\", \"random\"]\n",
    "similarity = [\"jaccard\", \"cosine\"]\n",
    "pop_boost = [0, 1]\n",
    "sknn_params = list(itertools.product(k, sampling, similarity, pop_boost))\n",
    "\n",
    "for i in range (len(sknn_params)):\n",
    "    trainSKNN((sknn_params[i])[0],(sknn_params[i])[1],(sknn_params[i])[2],(sknn_params[i])[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training S-sknn with same params as sknn\n",
    "\n",
    "for i in range(len(sknn_params)):\n",
    "    trainSsKNN((sknn_params[i])[0], (sknn_params[i])[1], (sknn_params[i])[2], (sknn_params[i])[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training SVKNN with same params as sknn\n",
    "\n",
    "weighting_fun = [\"div\", \"log\", \"quadratic\"]\n",
    "\n",
    "for i in range(len(sknn_params)):\n",
    "    for fun in weighting_fun:\n",
    "        trainSVMKNN((sknn_params[i])[0],(sknn_params[i])[1],(sknn_params[i])[2],(sknn_params[i])[3], fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
