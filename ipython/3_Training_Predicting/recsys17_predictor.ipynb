{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import Evaluation.metric_evaluation as eval\n",
    "#from Evaluation.Metrics import accuracy as ac\n",
    "import time\n",
    "import pickle\n",
    "import argparse\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from multiprocessing import Pool, cpu_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WithExtraArgs(object):\n",
    "    def __init__(self, func, **args):\n",
    "        self.func = func\n",
    "        self.args = args\n",
    "    def __call__(self, df):\n",
    "        return self.func(df, **self.args)\n",
    "\n",
    "def predict_function(test_session, pr, items_to_predict, cut_off=20, \n",
    "                     session_key='SessionId', item_key='ItemId', time_key='Time'):\n",
    "    test_session.sort_values([time_key], inplace=True)\n",
    "    # get first and only session_id (as we grouped it before calling this method)\n",
    "    session_id = test_session[session_key].unique()[0]\n",
    "\n",
    "    log_columns = [\"session_id\", \"input_items\", \"input_count\", \"position\", \"remaining_items\", \"remaining_count\", \"predictions\"]\n",
    "    log_df = pd.DataFrame(columns = log_columns)\n",
    "\n",
    "    session_length = len(test_session)\n",
    "    for i in range(session_length -1):\n",
    "        # use current item as reference point (rest is for testing)\n",
    "        current_item_id = test_session[item_key].values[i]\n",
    "        \n",
    "        # make predictions\n",
    "        preds = pr.predict_next(session_id, current_item_id, items_to_predict)\n",
    "        # extract top-n predicted items\n",
    "        preds[np.isnan(preds)] = 0\n",
    "        preds.sort_values( ascending=False, inplace=True )\n",
    "        \n",
    "        topn_preds = preds[:cut_off]\n",
    "        \n",
    "        # log results\n",
    "        current_input_set = test_session[item_key].values[:i+1]\n",
    "        remaining_test_set = test_session[item_key].values[i+1:]\n",
    "        position = \"MID\"\n",
    "        if i == 0:\n",
    "            position = \"FIRST\"\n",
    "        if len(remaining_test_set) == 1:\n",
    "            position = \"LAST\"\n",
    "        \n",
    "        # use np.array_str as the a new line charachter will be automatically set otherweise\n",
    "        log_df = log_df.append({\n",
    "            \"session_id\": session_id,\n",
    "            \"input_items\":  ','.join(map(str, current_input_set)),\n",
    "            \"input_count\":  len(current_input_set),\n",
    "            \"position\": position,\n",
    "            \"remaining_items\":  ','.join(map(str, remaining_test_set)),\n",
    "            \"remaining_count\":  len(remaining_test_set),\n",
    "            \"predictions\": ','.join(map(str, topn_preds.index.values))\n",
    "      }, ignore_index=True)\n",
    "    \n",
    "    \n",
    "    log_df['input_count'] = log_df['input_count'].astype(int)\n",
    "    log_df['remaining_count'] = log_df['remaining_count'].astype(int)\n",
    "    \n",
    "    return log_df\n",
    "\n",
    "def apply_parallel(dfGrouped, func, kwargs):\n",
    "    cpus = cpu_count()\n",
    "    #cpus = 1\n",
    "    with Pool(cpus) as p:\n",
    "        ret_list = p.map(WithExtraArgs(func, **kwargs), [group for name, group in dfGrouped])\n",
    "    return pd.concat(ret_list)\n",
    "\n",
    "def generate_predictions(pr, test_data, train_data, \n",
    "                         items=None, cut_off=20, algo_name=None, batch_size=100,\n",
    "                         session_key='SessionId', item_key='ItemId', time_key='Time'): \n",
    "    '''\n",
    "    Evaluates the algorithms wrt. the given metrics. Has no batch evaluation capabilities. \n",
    "\n",
    "    Parameters\n",
    "    --------\n",
    "    pr : baseline predictor\n",
    "        A trained instance of a baseline predictor.\n",
    "    metrics : list\n",
    "        A list of metric classes providing the proper methods\n",
    "    test_data : pandas.DataFrame\n",
    "        Test data. It contains the transactions of the test set.It has one column for session IDs, one for item IDs and one for the timestamp of the events (unix timestamps).\n",
    "        It must have a header. Column names are arbitrary, but must correspond to the keys you use in this function.\n",
    "    train_data : pandas.DataFrame\n",
    "        Training data. Only required for selecting the set of item IDs of the training set.\n",
    "    items : 1D list or None\n",
    "        The list of item ID that you want to compare the score of the relevant item to. If None, all items of the training set are used. Default value is None.\n",
    "    cut-off : int\n",
    "        Cut-off value (i.e. the length of the recommendation list; N for recall@N and MRR@N). Defauld value is 20.\n",
    "    batch_size : int\n",
    "        Number of events bundled into a batch during evaluation. Speeds up evaluation. \n",
    "        If it is set high, the memory consumption increases. Default value is 100.\n",
    "    session_key : string\n",
    "        Header of the session ID column in the input file (default: 'SessionId')\n",
    "    item_key : string\n",
    "        Header of the item ID column in the input file (default: 'ItemId')\n",
    "    time_key : string\n",
    "        Header of the timestamp column in the input file (default: 'Time')\n",
    "    \n",
    "    Returns\n",
    "    --------\n",
    "    out :  list of tuples\n",
    "        (metric_name, value)\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    actions = len(test_data)\n",
    "    sessions = len(test_data[session_key].unique())\n",
    "    count = 0\n",
    "    print('START evaluation of ', actions, ' actions in ', sessions, ' sessions')\n",
    "    \n",
    "    if algo_name is not \"gru\":\n",
    "        print(\"Running parallel prediction by session groups...\")\n",
    "        items_to_predict = train_data[item_key].unique()\n",
    "\n",
    "        session_groups = test_data.groupby(session_key)\n",
    "        # generate predictions in parallel using all cpu cores\n",
    "        res = apply_parallel(session_groups, predict_function, {\"pr\": pr, \"items_to_predict\": items_to_predict})\n",
    "        res = res.reindex(columns = [\"session_id\", \"input_items\", \"input_count\", \"position\", \"remaining_items\", \"remaining_count\", \"predictions\"])\n",
    "        return res\n",
    "    else:\n",
    "        print(\"Running batch prediction for Gru4rec...\")\n",
    "        test_data.sort_values([session_key, time_key], inplace=True)\n",
    "\n",
    "        offset_sessions = np.zeros(test_data[session_key].nunique()+1, dtype=np.int32)\n",
    "        offset_sessions[1:] = test_data.groupby(session_key).size().cumsum()\n",
    "        \n",
    "        if len(offset_sessions) - 1 < batch_size:\n",
    "            batch_size = len(offset_sessions) - 1\n",
    "        \n",
    "        iters = np.arange(batch_size).astype(np.int32) \n",
    "\n",
    "        maxiter = iters.max()    \n",
    "        start = offset_sessions[iters]\n",
    "        end = offset_sessions[iters+1]\n",
    "\n",
    "        in_idx = np.zeros(batch_size, dtype=np.int32)    \n",
    "        in_sessions = np.zeros(batch_size, dtype = object) \n",
    "        np.random.seed(42)\n",
    "        \n",
    "        lookup = {}\n",
    "        \n",
    "        log_columns = [\"session_id\", \"input_items\", \"input_count\", \"position\", \"remaining_items\", \"remaining_count\", \"predictions\"]\n",
    "        log_df = pd.DataFrame(columns = log_columns)\n",
    "      \n",
    "\n",
    "        while True:\n",
    "            valid_mask = iters >= 0\n",
    "            if valid_mask.sum() == 0:\n",
    "                break\n",
    "            \n",
    "            start_valid = start[valid_mask]        \n",
    "            minlen = (end[valid_mask]-start_valid).min()\n",
    "            in_idx[valid_mask] = test_data[item_key].values[start_valid]\n",
    "            in_sessions[valid_mask] = test_data[session_key].values[start_valid]\n",
    "\n",
    "            for i in range(minlen-1):\n",
    "                # expected output\n",
    "                out_idx = test_data[item_key].values[start_valid+i+1]\n",
    "                # make prediction\n",
    "                preds = pr.predict_next_batch(iters, in_idx, None, batch_size)\n",
    "                \n",
    "                preds.fillna(0, inplace=True)\n",
    "                # new in index becomes old out index\n",
    "                in_idx[valid_mask] = out_idx\n",
    "                \n",
    "                valid_sessions = in_sessions[valid_mask]\n",
    "                i=0\n",
    "                for part, series in preds.loc[:,valid_mask].iteritems(): \n",
    "                    # what is the current session\n",
    "                    curr_session = valid_sessions[i]\n",
    "                    # increment item index per session\n",
    "                    if curr_session in lookup:\n",
    "                        lookup[curr_session] += 1\n",
    "                    else:\n",
    "                        lookup[curr_session] = 0\n",
    "                    \n",
    "                    # current session's data\n",
    "                    cur_session_data = test_data.loc[test_data[session_key] == curr_session]\n",
    "                    # what were the current inputs\n",
    "                    history_items = cur_session_data.iloc[:lookup[curr_session] + 1][item_key]\n",
    "                    # expected outputs\n",
    "                    to_predict_items = cur_session_data.iloc[lookup[curr_session] + 1:][item_key]\n",
    "                    # get the top-n predictions\n",
    "                    preds.sort_values( part, ascending=False, inplace=True )\n",
    "                    topn_preds = preds[:cut_off]\n",
    "\n",
    "                    position = \"MID\"\n",
    "                    if len(history_items) == 0:\n",
    "                        position = \"FIRST\"\n",
    "                    if len(to_predict_items) == 1:\n",
    "                        position = \"LAST\"\n",
    "\n",
    "                    # use np.array_str as the a new line charachter will be automatically set otherweise\n",
    "                    log_df = log_df.append({\n",
    "                        \"session_id\": curr_session,\n",
    "                        \"input_items\":  ','.join(map(str, history_items)),\n",
    "                        \"input_count\":  len(history_items),\n",
    "                        \"position\": position,\n",
    "                        \"remaining_items\":  ','.join(map(str, to_predict_items)),\n",
    "                        \"remaining_count\":  len(to_predict_items),\n",
    "                        \"predictions\": ','.join(map(str, topn_preds.index.values))\n",
    "                    }, ignore_index=True)\n",
    "\n",
    "\n",
    "                    # m.add( preds[part], out_idx[i] )\n",
    "                    i += 1\n",
    "            start = start+minlen-1\n",
    "            mask = np.arange(len(iters))[(valid_mask) & (end-start<=1)]\n",
    "            for idx in mask:\n",
    "                maxiter += 1\n",
    "                if maxiter >= len(offset_sessions)-1:\n",
    "                    iters[idx] = -1\n",
    "                else:\n",
    "                    iters[idx] = maxiter\n",
    "                    start[idx] = offset_sessions[maxiter]\n",
    "                    end[idx] = offset_sessions[maxiter+1]\n",
    "    \n",
    "        log_df['input_count'] = log_df['input_count'].astype(int)\n",
    "        log_df['remaining_count'] = log_df['remaining_count'].astype(int)\n",
    "        return log_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "# Hyperparameter optimization models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: models/valid/recsys17_GRU4Rec_lossbpr-max-0.5_layers1000.model\n",
      "START evaluation of  5958  actions in  2046  sessions\n",
      "Running batch prediction for Gru4rec...\n",
      "Stored prediction results in: ../../data/recsys17/interim/predict/hyperparam/test_14d_GRU4Rec_lossbpr-max-0.5_layers1000.csv\n",
      "Loading model: models/valid/recsys17_GRU4Rec_losstop1-max_layers1000_1000.model\n",
      "START evaluation of  5958  actions in  2046  sessions\n",
      "Running batch prediction for Gru4rec...\n",
      "Stored prediction results in: ../../data/recsys17/interim/predict/hyperparam/test_14d_GRU4Rec_losstop1-max_layers1000_1000.csv\n",
      "Loading model: models/valid/recsys17_GRU4Rec_lossbpr-max-0.5_layers1000_1000.model\n",
      "START evaluation of  5958  actions in  2046  sessions\n",
      "Running batch prediction for Gru4rec...\n",
      "Stored prediction results in: ../../data/recsys17/interim/predict/hyperparam/test_14d_GRU4Rec_lossbpr-max-0.5_layers1000_1000.csv\n",
      "Loading model: models/valid/recsys17_GRU4Rec_losstop1-max_layers100_100.model\n",
      "START evaluation of  5958  actions in  2046  sessions\n",
      "Running batch prediction for Gru4rec...\n",
      "Stored prediction results in: ../../data/recsys17/interim/predict/hyperparam/test_14d_GRU4Rec_losstop1-max_layers100_100.csv\n",
      "Loading model: models/valid/recsys17_GRU4Rec_lossbpr-max-0.5_layers100_100.model\n",
      "START evaluation of  5958  actions in  2046  sessions\n",
      "Running batch prediction for Gru4rec...\n",
      "Stored prediction results in: ../../data/recsys17/interim/predict/hyperparam/test_14d_GRU4Rec_lossbpr-max-0.5_layers100_100.csv\n",
      "Loading model: models/valid/recsys17_GRU4Rec_lossbpr-max-0.5_layers100.model\n",
      "START evaluation of  5958  actions in  2046  sessions\n",
      "Running batch prediction for Gru4rec...\n",
      "Stored prediction results in: ../../data/recsys17/interim/predict/hyperparam/test_14d_GRU4Rec_lossbpr-max-0.5_layers100.csv\n",
      "Loading model: models/valid/recsys17_GRU4Rec_losstop1-max_layers100.model\n",
      "START evaluation of  5958  actions in  2046  sessions\n",
      "Running batch prediction for Gru4rec...\n",
      "Stored prediction results in: ../../data/recsys17/interim/predict/hyperparam/test_14d_GRU4Rec_losstop1-max_layers100.csv\n",
      "Loading model: models/valid/recsys17_GRU4Rec_losstop1-max_layers1000.model\n",
      "START evaluation of  5958  actions in  2046  sessions\n",
      "Running batch prediction for Gru4rec...\n",
      "Stored prediction results in: ../../data/recsys17/interim/predict/hyperparam/test_14d_GRU4Rec_losstop1-max_layers1000.csv\n"
     ]
    }
   ],
   "source": [
    "store_path = \"../../data/recsys17/processed/\"\n",
    "predict_path = \"../../data/recsys17/interim/predict/hyperparam/\"\n",
    "\n",
    "valid_models_path = \"models/valid\"\n",
    "\n",
    "train  = pd.read_csv(store_path + \"valid_train_14d.csv\", sep='\\t', dtype={'item_id':np.int64})[['session_id','item_id','created_at']]\n",
    "test = pd.read_csv(store_path + \"valid_test_14d.csv\", sep='\\t', dtype={'item_id':np.int64})[['session_id','item_id','created_at']]\n",
    "\n",
    "train.columns = ['SessionId', 'ItemId', 'Time']\n",
    "test.columns = ['SessionId', 'ItemId', 'Time']\n",
    "\n",
    "for f in listdir(valid_models_path):\n",
    "    file_path = join(valid_models_path, f)\n",
    "    if isfile(file_path):\n",
    "        #if \"recsys17\" in f:\n",
    "        if \"recsys17\" in f and \"GRU4Rec\" in f:\n",
    "            print(\"Loading model: \" + file_path)\n",
    "            loaded_model = pickle.load(open(file_path, 'rb'))\n",
    "            algo = f.replace(\"recsys17_\",\"\").replace(\".model\",\"\")\n",
    "            #res_log = generate_predictions(loaded_model, test, train, algo_name = algo)\n",
    "            res_log = generate_predictions(loaded_model, test, train, algo_name = \"gru\")\n",
    "            res_log.to_csv(predict_path + \"test_14d_\" + algo + \".csv\", sep='\\t')\n",
    "            print(\"Stored prediction results in: \" + predict_path + \"test_14d_\" + algo + \".csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_algo(algo):\n",
    "    load_path = \"../../data/recsys17/processed/\"\n",
    "\n",
    "    train  = pd.read_csv(load_path + \"train_14d.csv\", sep='\\t', dtype={'item_id':np.int64})[['session_id','item_id','created_at']]\n",
    "    test = pd.read_csv(load_path + \"test_14d.csv\", sep='\\t', dtype={'item_id':np.int64})[['session_id','item_id','created_at']]\n",
    "\n",
    "    train.columns = ['SessionId', 'ItemId', 'Time']\n",
    "    test.columns = ['SessionId', 'ItemId', 'Time']\n",
    "    \n",
    "    filename = \"models/recsys17_\"  + algo + \".model\"\n",
    "    print(\"Loading model: \" + filename)\n",
    "    loaded_model = pickle.load(open(filename, 'rb'))\n",
    "    \n",
    "    res_log = generate_predictions(loaded_model, test, train, algo_name = algo)\n",
    "    \n",
    "    store_path = \"../../data/recsys17/interim/predict/base/\"\n",
    "    res_log.to_csv(store_path + \"test_14d_\" + algo + \".csv\", sep='\\t')\n",
    "    print(\"Stored prediction results in: \" + store_path + \"test_14d_\" + algo + \".csv\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: models/recsys17_pop.model\n",
      "START evaluation of  8498  actions in  3610  sessions\n",
      "Running parallel prediction by session groups...\n",
      "Stored prediction results in: ../../data/recsys17/interim/predict/base/test_14d_pop.csv\n",
      "Loading model: models/recsys17_iknn.model\n",
      "START evaluation of  8498  actions in  3610  sessions\n",
      "Running parallel prediction by session groups...\n",
      "Stored prediction results in: ../../data/recsys17/interim/predict/base/test_14d_iknn.csv\n",
      "Loading model: models/recsys17_bpr.model\n",
      "START evaluation of  8498  actions in  3610  sessions\n",
      "Running parallel prediction by session groups...\n",
      "Stored prediction results in: ../../data/recsys17/interim/predict/base/test_14d_bpr.csv\n",
      "Loading model: models/recsys17_cknn.model\n",
      "START evaluation of  8498  actions in  3610  sessions\n",
      "Running parallel prediction by session groups...\n",
      "Stored prediction results in: ../../data/recsys17/interim/predict/base/test_14d_cknn.csv\n",
      "Loading model: models/recsys17_scknn.model\n",
      "START evaluation of  8498  actions in  3610  sessions\n",
      "Running parallel prediction by session groups...\n",
      "Stored prediction results in: ../../data/recsys17/interim/predict/base/test_14d_scknn.csv\n",
      "Loading model: models/recsys17_vcknn.model\n",
      "START evaluation of  8498  actions in  3610  sessions\n",
      "Running parallel prediction by session groups...\n",
      "Stored prediction results in: ../../data/recsys17/interim/predict/base/test_14d_vcknn.csv\n",
      "Loading model: models/recsys17_gru.model\n",
      "START evaluation of  8498  actions in  3610  sessions\n",
      "Running batch prediction for Gru4rec...\n",
      "Stored prediction results in: ../../data/recsys17/interim/predict/base/test_14d_gru.csv\n"
     ]
    }
   ],
   "source": [
    "predict_algo(\"pop\")\n",
    "predict_algo(\"iknn\")\n",
    "predict_algo(\"bpr\")\n",
    "predict_algo(\"cknn\")\n",
    "predict_algo(\"scknn\")\n",
    "predict_algo(\"vcknn\")\n",
    "predict_algo(\"gru\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: ../data/recsys17/interim/models/gru.model\n",
      "START evaluation of  8498  actions in  3610  sessions\n",
      "Running batch prediction for Gru4rec...\n",
      "Stored prediction results in: ../data/recsys17/interim/predict/base_test_14d_gru.csv\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# PREDICT\n",
    "# ---------------------------\n",
    "# ---------------------------\n",
    "\n",
    "algo = \"gru\" # pop, spop, iknn, cknn, bpr, gru\n",
    "\n",
    "load_path = \"../data/recsys17/processed/\"\n",
    "\n",
    "train  = pd.read_csv(load_path + \"train_14d.csv\", sep='\\t', dtype={'item_id':np.int64})[['session_id','item_id','created_at']]\n",
    "test = pd.read_csv(load_path + \"test_14d.csv\", sep='\\t', dtype={'item_id':np.int64})[['session_id','item_id','created_at']]\n",
    "\n",
    "train.columns = ['SessionId', 'ItemId', 'Time']\n",
    "test.columns = ['SessionId', 'ItemId', 'Time']\n",
    "\n",
    "filename = \"../data/recsys17/interim/models/\"  + algo + \".model\"\n",
    "\n",
    "print(\"Loading model: \" + filename)\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "res_log = generate_predictions(loaded_model, test, train, algo_name = algo)\n",
    "\n",
    "store_path = \"../data/recsys17/interim/predict/base_\"\n",
    "res_log.to_csv(store_path + \"test_14d_\" + algo + \".csv\", sep='\\t')\n",
    "print(\"Stored prediction results in: \" + store_path + \"test_14d_\" + algo + \".csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: Models/no_repeat_recsys17_gru.model\n",
      "START evaluation of  2594  actions in  997  sessions\n",
      "Running batch prediction for Gru4rec...\n",
      "Stored prediction results in: ../results/recsys17/base/no_repeat_test_d14_gru.csv\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# PREDICT\n",
    "# ---------------------------\n",
    "# ---------------------------\n",
    "store_path = \"../data/recsys17/\"\n",
    "\n",
    "train  = pd.read_csv(store_path + \"train_d14.csv\", sep='\\t', dtype={'item_id':np.int64})[['session_id','item_id','created_at']]\n",
    "test = pd.read_csv(store_path + \"test_d14.csv\", sep='\\t', dtype={'item_id':np.int64})[['session_id','item_id','created_at']]\n",
    "\n",
    "train.columns = ['SessionId', 'ItemId', 'Time']\n",
    "test.columns = ['SessionId', 'ItemId', 'Time']\n",
    "\n",
    "algo = \"gru\"\n",
    "filename = \"Models/recsys17_\"  + algo + \".model\"\n",
    "\n",
    "print(\"Loading model: \" + filename)\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "res_log = generate_predictions(loaded_model, test, train, algo_name = algo)\n",
    "\n",
    "store_path = \"../results/recsys17/base/\"\n",
    "res_log.to_csv(store_path + \"test_d14_\" + algo + \".csv\", sep='\\t')\n",
    "print(\"Stored prediction results in: \" + store_path + \"test_d14_\" + algo + \".csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
